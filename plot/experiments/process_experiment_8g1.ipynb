{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"/home/gonzaeve/boids/leader-follower\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from leaderfollower.file_helper import loadBatch, loadConfigData\n",
    "from leaderfollower.plot_helpers import plotBatchPerformance, PerformanceMetric\n",
    "from leaderfollower.data_helpers import getEvalFitnesses\n",
    "import matplotlib\n",
    "font = {\n",
    "        # 'family' : 'Helvetica',\n",
    "        # 'weight' : 'bold',\n",
    "        'size'   : 15}\n",
    "matplotlib.rc('font', **font)\n",
    "# As far as I can tell, matplotlib inline isn't supported for running a jupyter notebook with vscode\n",
    "# But this line should work for interactive figures for working within a jupyter notebook outside vscode\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G trials:  ['trial_0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 38.53it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load in the batch data\"\"\"\n",
    "start_trial_num = 0\n",
    "num_stat_runs = 1\n",
    "computername = \"experiment_8g1\"\n",
    "\n",
    "tested_G = True\n",
    "tested_D = False\n",
    "tested_Dfollow = False\n",
    "\n",
    "num_generations, trial_datas_Dfollow, trial_datas_D, trial_datas_G = loadBatch(\n",
    "    computername=computername,\n",
    "    start_trial_num=start_trial_num,\n",
    "    num_stat_runs=num_stat_runs,\n",
    "    tested_G=tested_G,\n",
    "    tested_D=tested_D,\n",
    "    tested_Dfollow=tested_Dfollow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot as  figures/trial_0 | stat_runs 1 | Evaluation Team | G | std err | experiment_8g1.png\n",
      "Saving plot as  figures/trial_0 | stat_runs 1 | Evaluation Team | G | std err | experiment_8g1.svg\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Plot the evaluation team performance metric\"\"\"\n",
    "plot_min_max_range = False\n",
    "\n",
    "plotBatchPerformance(\n",
    "    trial_datas_G=trial_datas_G,\n",
    "    trial_datas_D=trial_datas_D,\n",
    "    trial_datas_Dfollow=trial_datas_Dfollow,\n",
    "    plot_min_max_range=plot_min_max_range,\n",
    "    start_trial_num=start_trial_num,\n",
    "    num_stat_runs=num_stat_runs,\n",
    "    computername=computername,\n",
    "    performance_metric=PerformanceMetric.EvaluationTeam\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot as  figures/trial_0 | stat_runs 1 | Best Training Team | G | full range | experiment_8g1.png\n",
      "Saving plot as  figures/trial_0 | stat_runs 1 | Best Training Team | G | full range | experiment_8g1.svg\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Plot the best training team performance metric\"\"\"\n",
    "plot_min_max_range = True\n",
    "\n",
    "plotBatchPerformance(\n",
    "    trial_datas_G=trial_datas_G,\n",
    "    trial_datas_D=trial_datas_D,\n",
    "    trial_datas_Dfollow=trial_datas_Dfollow,\n",
    "    plot_min_max_range=plot_min_max_range,\n",
    "    start_trial_num=start_trial_num,\n",
    "    num_stat_runs=num_stat_runs,\n",
    "    computername=computername,\n",
    "    performance_metric=PerformanceMetric.BestTrainingTeam\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Aggregate data for the more detailed plot of trial performances\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# G, D, then Dfollow\u001b[39;00m\n\u001b[1;32m      4\u001b[0m trial_data_0 \u001b[39m=\u001b[39m trial_datas_G[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m trial_data_1 \u001b[39m=\u001b[39m trial_datas_G[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m      6\u001b[0m trial_data_2 \u001b[39m=\u001b[39m trial_datas_G[\u001b[39m2\u001b[39m]\n\u001b[1;32m      8\u001b[0m trial_data_3 \u001b[39m=\u001b[39m trial_datas_D[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Aggregate data for the more detailed plot of trial performances\n",
    "\n",
    "# G, D, then Dfollow\n",
    "trial_data_0 = trial_datas_G[0]\n",
    "trial_data_1 = trial_datas_G[1]\n",
    "trial_data_2 = trial_datas_G[2]\n",
    "\n",
    "trial_data_3 = trial_datas_D[0]\n",
    "trial_data_4 = trial_datas_D[1]\n",
    "trial_data_5 = trial_datas_D[2]\n",
    "\n",
    "trial_data_6 = trial_datas_Dfollow[0]\n",
    "trial_data_7 = trial_datas_Dfollow[1]\n",
    "trial_data_8 = trial_datas_Dfollow[2]\n",
    "\n",
    "team_fitness_0, agent_fitnesses_0 = getEvalFitnesses(trial_data_0)\n",
    "team_fitness_1, agent_fitnesses_1 = getEvalFitnesses(trial_data_1)\n",
    "team_fitness_2, agent_fitnesses_2 = getEvalFitnesses(trial_data_2)\n",
    "\n",
    "team_fitness_3, agent_fitnesses_3 = getEvalFitnesses(trial_data_3)\n",
    "team_fitness_4, agent_fitnesses_4 = getEvalFitnesses(trial_data_4)\n",
    "team_fitness_5, agent_fitnesses_5 = getEvalFitnesses(trial_data_5)\n",
    "\n",
    "team_fitness_6, agent_fitnesses_6 = getEvalFitnesses(trial_data_6)\n",
    "team_fitness_7, agent_fitnesses_7 = getEvalFitnesses(trial_data_7)\n",
    "team_fitness_8, agent_fitnesses_8 = getEvalFitnesses(trial_data_8)\n",
    "\n",
    "config = loadConfigData(trialname=\"trial_0\", computername=\"experiment_8g\")\n",
    "leader_colors = config[\"CCEA\"][\"config\"][\"BoidsEnv\"][\"config\"][\"Renderer\"][\"leader_colors\"]\n",
    "leader_colors = tuple(np.array(leader_colors)/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(team_fitness_0, color=\"royalblue\", linestyle=\"-\")\n",
    "plt.plot(team_fitness_1, color=\"navy\", linestyle=\"-\")\n",
    "plt.plot(team_fitness_2, color=\"blue\", linestyle=\"-\")\n",
    "\n",
    "plt.plot(team_fitness_3, color=\"darkorange\", linestyle=\"-\")\n",
    "plt.plot(team_fitness_4, color=\"navajowhite\", linestyle=\"-\")\n",
    "plt.plot(team_fitness_5, color=\"orange\", linestyle=\"-\")\n",
    "\n",
    "plt.plot(team_fitness_6, color=\"forestgreen\", linestyle=\"-\")\n",
    "plt.plot(team_fitness_7, color=\"limegreen\", linestyle=\"-\")\n",
    "plt.plot(team_fitness_8, color=\"darkgreen\", linestyle=\"-\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
